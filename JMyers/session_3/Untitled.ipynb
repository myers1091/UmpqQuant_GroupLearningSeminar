{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9710edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6455399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 18:31:37.875948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:37.881117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:37.881771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))#Check if GPU found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006b377",
   "metadata": {},
   "source": [
    "#Let's bring in the wrapper from te chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e357e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation=\"elu\",\n",
    "                          kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20516e",
   "metadata": {},
   "source": [
    "Bring in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f9d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (50000, 32, 32, 3) ytrain (50000, 1) Xtest (10000, 32, 32, 3) ytest (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train_full,y_train_full),(X_test,y_test) = keras.datasets.cifar10.load_data()# Read data\n",
    "print(\"Xtrain\",X_train_full.shape,\"ytrain\",y_train_full.shape,\\\n",
    "      \"Xtest\",X_test.shape,\"ytest\",y_test.shape)#print off shapes to make sure they match what book says\n",
    "X_train_full = X_train_full.astype('float32')/255.0#\n",
    "X_test = X_test.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a03562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 18:31:43.470335: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-19 18:31:43.472041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:43.473390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:43.474658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:43.820930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:43.821608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:43.822244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 18:31:43.822879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21766 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "y_test_OH = tf.one_hot(y_test, 10)\n",
    "y_train_full_OH = tf.one_hot(y_train_full, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35aed1",
   "metadata": {},
   "source": [
    "Create DNN with 20 hidden layers of 100 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d733a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 17:41:31.669377: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-19 17:41:31.670899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 17:41:31.672207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 17:41:31.673420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 17:41:31.996050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 17:41:31.996681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 17:41:31.997265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-19 17:41:31.997849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21740 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Flatten(input_shape=[32,32,3])])\n",
    "for i in range(1,21):\n",
    "    model.add(RegularizedDense(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4948e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "190d381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd58b2",
   "metadata": {},
   "source": [
    "Part b <br>\n",
    "Use Nadam optimization and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75136400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\\\n",
    "              optimizer=\"Nadam\",\\\n",
    "              metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f8b75",
   "metadata": {},
   "source": [
    "Define exponential decay LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6d7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0,s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch/s)\n",
    "    return exponential_decay_fn\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35fdb7",
   "metadata": {},
   "source": [
    "Define our Callbacks (LR and early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e39cb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61184407",
   "metadata": {},
   "source": [
    "Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb3d1caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 2.4032 - categorical_accuracy: 0.1112 - val_loss: 2.4623 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3776 - categorical_accuracy: 0.0904 - val_loss: 2.3520 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0089\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3631 - categorical_accuracy: 0.0864 - val_loss: 2.3434 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0079\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3535 - categorical_accuracy: 0.1056 - val_loss: 2.3691 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0071\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3467 - categorical_accuracy: 0.1136 - val_loss: 2.3465 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0063\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3434 - categorical_accuracy: 0.1136 - val_loss: 2.3392 - val_categorical_accuracy: 1.0000 - lr: 0.0056\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3387 - categorical_accuracy: 0.0840 - val_loss: 2.3422 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0050\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3355 - categorical_accuracy: 0.0920 - val_loss: 2.3310 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0045\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3347 - categorical_accuracy: 0.1224 - val_loss: 2.3242 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3310 - categorical_accuracy: 0.0824 - val_loss: 2.3268 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0035\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3312 - categorical_accuracy: 0.0776 - val_loss: 2.3291 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3262 - categorical_accuracy: 0.1104 - val_loss: 2.3267 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0028\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3269 - categorical_accuracy: 0.0928 - val_loss: 2.3217 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3239 - categorical_accuracy: 0.0832 - val_loss: 2.3346 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0022\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3225 - categorical_accuracy: 0.1104 - val_loss: 2.3118 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0020\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3211 - categorical_accuracy: 0.1016 - val_loss: 2.3146 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0018\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3194 - categorical_accuracy: 0.0832 - val_loss: 2.3178 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0016\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3172 - categorical_accuracy: 0.0592 - val_loss: 2.3104 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0014\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3172 - categorical_accuracy: 0.1488 - val_loss: 2.3122 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0013\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3153 - categorical_accuracy: 0.0920 - val_loss: 2.3241 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0011\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3134 - categorical_accuracy: 0.1400 - val_loss: 2.3127 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3128 - categorical_accuracy: 0.1040 - val_loss: 2.3197 - val_categorical_accuracy: 1.0000 - lr: 8.9125e-04\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3115 - categorical_accuracy: 0.0808 - val_loss: 2.3150 - val_categorical_accuracy: 1.0000 - lr: 7.9433e-04\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3123 - categorical_accuracy: 0.0728 - val_loss: 2.3091 - val_categorical_accuracy: 0.0000e+00 - lr: 7.0795e-04\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3105 - categorical_accuracy: 0.1176 - val_loss: 2.3071 - val_categorical_accuracy: 0.0000e+00 - lr: 6.3096e-04\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3090 - categorical_accuracy: 0.1168 - val_loss: 2.3056 - val_categorical_accuracy: 0.0000e+00 - lr: 5.6234e-04\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3085 - categorical_accuracy: 0.0872 - val_loss: 2.3171 - val_categorical_accuracy: 0.0000e+00 - lr: 5.0119e-04\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3086 - categorical_accuracy: 0.0960 - val_loss: 2.3067 - val_categorical_accuracy: 0.0000e+00 - lr: 4.4668e-04\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3079 - categorical_accuracy: 0.0856 - val_loss: 2.3096 - val_categorical_accuracy: 0.0000e+00 - lr: 3.9811e-04\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3075 - categorical_accuracy: 0.0768 - val_loss: 2.3044 - val_categorical_accuracy: 0.0000e+00 - lr: 3.5481e-04\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3067 - categorical_accuracy: 0.0856 - val_loss: 2.3044 - val_categorical_accuracy: 0.0000e+00 - lr: 3.1623e-04\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3060 - categorical_accuracy: 0.0776 - val_loss: 2.3119 - val_categorical_accuracy: 0.0000e+00 - lr: 2.8184e-04\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3058 - categorical_accuracy: 0.1048 - val_loss: 2.3046 - val_categorical_accuracy: 0.0000e+00 - lr: 2.5119e-04\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3053 - categorical_accuracy: 0.0528 - val_loss: 2.3058 - val_categorical_accuracy: 0.0000e+00 - lr: 2.2387e-04\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3056 - categorical_accuracy: 0.1016 - val_loss: 2.3040 - val_categorical_accuracy: 0.0000e+00 - lr: 1.9953e-04\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3049 - categorical_accuracy: 0.0416 - val_loss: 2.3044 - val_categorical_accuracy: 0.0000e+00 - lr: 1.7783e-04\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3048 - categorical_accuracy: 0.0816 - val_loss: 2.3058 - val_categorical_accuracy: 0.0000e+00 - lr: 1.5849e-04\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3045 - categorical_accuracy: 0.1384 - val_loss: 2.3043 - val_categorical_accuracy: 0.0000e+00 - lr: 1.4125e-04\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3043 - categorical_accuracy: 0.0688 - val_loss: 2.3065 - val_categorical_accuracy: 0.0000e+00 - lr: 1.2589e-04\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3043 - categorical_accuracy: 0.0816 - val_loss: 2.3039 - val_categorical_accuracy: 1.0000 - lr: 1.1220e-04\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3039 - categorical_accuracy: 0.0800 - val_loss: 2.3059 - val_categorical_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3036 - categorical_accuracy: 0.0608 - val_loss: 2.3040 - val_categorical_accuracy: 0.0000e+00 - lr: 8.9125e-05\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3037 - categorical_accuracy: 0.0568 - val_loss: 2.3031 - val_categorical_accuracy: 0.0000e+00 - lr: 7.9433e-05\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3036 - categorical_accuracy: 0.1032 - val_loss: 2.3032 - val_categorical_accuracy: 0.0000e+00 - lr: 7.0795e-05\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3035 - categorical_accuracy: 0.0152 - val_loss: 2.3034 - val_categorical_accuracy: 0.0000e+00 - lr: 6.3096e-05\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3034 - categorical_accuracy: 0.0680 - val_loss: 2.3030 - val_categorical_accuracy: 0.0000e+00 - lr: 5.6234e-05\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3035 - categorical_accuracy: 0.0496 - val_loss: 2.3036 - val_categorical_accuracy: 0.0000e+00 - lr: 5.0119e-05\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3032 - categorical_accuracy: 0.0632 - val_loss: 2.3034 - val_categorical_accuracy: 0.0000e+00 - lr: 4.4668e-05\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3033 - categorical_accuracy: 0.1776 - val_loss: 2.3026 - val_categorical_accuracy: 0.0000e+00 - lr: 3.9811e-05\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3032 - categorical_accuracy: 0.1800 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 3.5481e-05\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3031 - categorical_accuracy: 8.0000e-04 - val_loss: 2.3032 - val_categorical_accuracy: 0.0000e+00 - lr: 3.1623e-05\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3031 - categorical_accuracy: 0.0904 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 2.8184e-05\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3030 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3033 - val_categorical_accuracy: 0.0000e+00 - lr: 2.5119e-05\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3030 - categorical_accuracy: 0.1128 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 2.2387e-05\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3030 - categorical_accuracy: 0.0064 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.9953e-05\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3029 - categorical_accuracy: 0.0680 - val_loss: 2.3027 - val_categorical_accuracy: 1.0000 - lr: 1.7783e-05\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3028 - categorical_accuracy: 0.0640 - val_loss: 2.3031 - val_categorical_accuracy: 0.0000e+00 - lr: 1.5849e-05\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3028 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 1.4125e-05\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3028 - categorical_accuracy: 0.0912 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 1.2589e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train_full,\\\n",
    "                    y_train_full,\\\n",
    "                    epochs=100,\\\n",
    "                    validation_split=0.2,\\\n",
    "                   callbacks=[early_stop_cb,lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6bb9c2",
   "metadata": {},
   "source": [
    "add batch normilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08df2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3072)             12288     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " activation_16 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bn = keras.models.Sequential([keras.layers.Flatten(input_shape=[32,32,3])])\n",
    "model_bn.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for i in range(1,21):\n",
    "    model_bn.add(keras.layers.Dense(100,kernel_initializer=\"he_normal\"))\n",
    "    model_bn.add(keras.layers.BatchNormalization())\n",
    "    model_bn.add(keras.layers.Activation(\"elu\"))\n",
    "model_bn.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "model_bn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cff1e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\\\n",
    "              optimizer=\"Nadam\",\\\n",
    "              metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7151a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1250/1250 [==============================] - 23s 15ms/step - loss: 1.3510 - categorical_accuracy: 0.1085 - val_loss: 1.7844 - val_categorical_accuracy: 0.0649 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.3318 - categorical_accuracy: 0.1091 - val_loss: 2.2230 - val_categorical_accuracy: 0.0310 - lr: 0.0089\n",
      "Epoch 3/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.3026 - categorical_accuracy: 0.1055 - val_loss: 1.5323 - val_categorical_accuracy: 0.0811 - lr: 0.0079\n",
      "Epoch 4/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 1.2717 - categorical_accuracy: 0.1068 - val_loss: 1.5352 - val_categorical_accuracy: 0.0788 - lr: 0.0071\n",
      "Epoch 5/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.2476 - categorical_accuracy: 0.1068 - val_loss: 1.4388 - val_categorical_accuracy: 0.1052 - lr: 0.0063\n",
      "Epoch 6/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.2109 - categorical_accuracy: 0.1083 - val_loss: 1.4965 - val_categorical_accuracy: 0.0645 - lr: 0.0056\n",
      "Epoch 7/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.1839 - categorical_accuracy: 0.1067 - val_loss: 1.4719 - val_categorical_accuracy: 0.0936 - lr: 0.0050\n",
      "Epoch 8/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.1623 - categorical_accuracy: 0.1063 - val_loss: 1.4579 - val_categorical_accuracy: 0.0611 - lr: 0.0045\n",
      "Epoch 9/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.1379 - categorical_accuracy: 0.1097 - val_loss: 1.4454 - val_categorical_accuracy: 0.0988 - lr: 0.0040\n",
      "Epoch 10/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 1.1180 - categorical_accuracy: 0.1095 - val_loss: 1.4542 - val_categorical_accuracy: 0.0963 - lr: 0.0035\n",
      "Epoch 11/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.1015 - categorical_accuracy: 0.1082 - val_loss: 1.4285 - val_categorical_accuracy: 0.0959 - lr: 0.0032\n",
      "Epoch 12/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0825 - categorical_accuracy: 0.1074 - val_loss: 1.4235 - val_categorical_accuracy: 0.1069 - lr: 0.0028\n",
      "Epoch 13/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0681 - categorical_accuracy: 0.1076 - val_loss: 1.4430 - val_categorical_accuracy: 0.1051 - lr: 0.0025\n",
      "Epoch 14/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0476 - categorical_accuracy: 0.1075 - val_loss: 1.4107 - val_categorical_accuracy: 0.1035 - lr: 0.0022\n",
      "Epoch 15/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0350 - categorical_accuracy: 0.1067 - val_loss: 1.4315 - val_categorical_accuracy: 0.0998 - lr: 0.0020\n",
      "Epoch 16/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0293 - categorical_accuracy: 0.1083 - val_loss: 1.4397 - val_categorical_accuracy: 0.1013 - lr: 0.0018\n",
      "Epoch 17/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.0084 - categorical_accuracy: 0.1066 - val_loss: 1.4439 - val_categorical_accuracy: 0.1267 - lr: 0.0016\n",
      "Epoch 18/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9983 - categorical_accuracy: 0.1088 - val_loss: 1.4461 - val_categorical_accuracy: 0.1183 - lr: 0.0014\n",
      "Epoch 19/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9978 - categorical_accuracy: 0.1071 - val_loss: 1.4554 - val_categorical_accuracy: 0.1068 - lr: 0.0013\n",
      "Epoch 20/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9841 - categorical_accuracy: 0.1061 - val_loss: 1.4506 - val_categorical_accuracy: 0.1040 - lr: 0.0011\n",
      "Epoch 21/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9788 - categorical_accuracy: 0.1065 - val_loss: 1.4548 - val_categorical_accuracy: 0.1111 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9750 - categorical_accuracy: 0.1059 - val_loss: 1.4525 - val_categorical_accuracy: 0.1077 - lr: 8.9125e-04\n",
      "Epoch 23/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9639 - categorical_accuracy: 0.1070 - val_loss: 1.4500 - val_categorical_accuracy: 0.1069 - lr: 7.9433e-04\n",
      "Epoch 24/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9588 - categorical_accuracy: 0.1080 - val_loss: 1.4609 - val_categorical_accuracy: 0.1084 - lr: 7.0795e-04\n",
      "Epoch 25/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9594 - categorical_accuracy: 0.1066 - val_loss: 1.4557 - val_categorical_accuracy: 0.1065 - lr: 6.3096e-04\n",
      "Epoch 26/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9421 - categorical_accuracy: 0.1072 - val_loss: 1.4746 - val_categorical_accuracy: 0.1103 - lr: 5.6234e-04\n",
      "Epoch 27/1000\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 0.9400 - categorical_accuracy: 0.1058 - val_loss: 1.4692 - val_categorical_accuracy: 0.1000 - lr: 5.0119e-04\n",
      "Epoch 28/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9410 - categorical_accuracy: 0.1062 - val_loss: 1.4624 - val_categorical_accuracy: 0.1091 - lr: 4.4668e-04\n",
      "Epoch 29/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9355 - categorical_accuracy: 0.1070 - val_loss: 1.4674 - val_categorical_accuracy: 0.1057 - lr: 3.9811e-04\n",
      "Epoch 30/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9357 - categorical_accuracy: 0.1063 - val_loss: 1.4626 - val_categorical_accuracy: 0.1062 - lr: 3.5481e-04\n",
      "Epoch 31/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9285 - categorical_accuracy: 0.1058 - val_loss: 1.4695 - val_categorical_accuracy: 0.1029 - lr: 3.1623e-04\n",
      "Epoch 32/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9292 - categorical_accuracy: 0.1045 - val_loss: 1.4713 - val_categorical_accuracy: 0.1131 - lr: 2.8184e-04\n",
      "Epoch 33/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9314 - categorical_accuracy: 0.1073 - val_loss: 1.4713 - val_categorical_accuracy: 0.1048 - lr: 2.5119e-04\n",
      "Epoch 34/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9263 - categorical_accuracy: 0.1046 - val_loss: 1.4797 - val_categorical_accuracy: 0.1127 - lr: 2.2387e-04\n",
      "Epoch 35/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9209 - categorical_accuracy: 0.1063 - val_loss: 1.4763 - val_categorical_accuracy: 0.1075 - lr: 1.9953e-04\n",
      "Epoch 36/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9223 - categorical_accuracy: 0.1058 - val_loss: 1.4724 - val_categorical_accuracy: 0.1077 - lr: 1.7783e-04\n",
      "Epoch 37/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9189 - categorical_accuracy: 0.1071 - val_loss: 1.4798 - val_categorical_accuracy: 0.1091 - lr: 1.5849e-04\n",
      "Epoch 38/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9168 - categorical_accuracy: 0.1062 - val_loss: 1.4787 - val_categorical_accuracy: 0.1038 - lr: 1.4125e-04\n",
      "Epoch 39/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9190 - categorical_accuracy: 0.1068 - val_loss: 1.4789 - val_categorical_accuracy: 0.1074 - lr: 1.2589e-04\n",
      "Epoch 40/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9163 - categorical_accuracy: 0.1054 - val_loss: 1.4758 - val_categorical_accuracy: 0.1092 - lr: 1.1220e-04\n",
      "Epoch 41/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9117 - categorical_accuracy: 0.1065 - val_loss: 1.4772 - val_categorical_accuracy: 0.1058 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9153 - categorical_accuracy: 0.1061 - val_loss: 1.4803 - val_categorical_accuracy: 0.1071 - lr: 8.9125e-05\n",
      "Epoch 43/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9212 - categorical_accuracy: 0.1046 - val_loss: 1.4784 - val_categorical_accuracy: 0.1080 - lr: 7.9433e-05\n",
      "Epoch 44/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9114 - categorical_accuracy: 0.1066 - val_loss: 1.4777 - val_categorical_accuracy: 0.1056 - lr: 7.0795e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9103 - categorical_accuracy: 0.1053 - val_loss: 1.4814 - val_categorical_accuracy: 0.1085 - lr: 6.3096e-05\n",
      "Epoch 46/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9154 - categorical_accuracy: 0.1061 - val_loss: 1.4781 - val_categorical_accuracy: 0.1075 - lr: 5.6234e-05\n",
      "Epoch 47/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9067 - categorical_accuracy: 0.1053 - val_loss: 1.4776 - val_categorical_accuracy: 0.1070 - lr: 5.0119e-05\n",
      "Epoch 48/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9143 - categorical_accuracy: 0.1055 - val_loss: 1.4790 - val_categorical_accuracy: 0.1070 - lr: 4.4668e-05\n",
      "Epoch 49/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9077 - categorical_accuracy: 0.1052 - val_loss: 1.4774 - val_categorical_accuracy: 0.1054 - lr: 3.9811e-05\n",
      "Epoch 50/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9084 - categorical_accuracy: 0.1055 - val_loss: 1.4837 - val_categorical_accuracy: 0.1061 - lr: 3.5481e-05\n",
      "Epoch 51/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9148 - categorical_accuracy: 0.1063 - val_loss: 1.4803 - val_categorical_accuracy: 0.1037 - lr: 3.1623e-05\n",
      "Epoch 52/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9095 - categorical_accuracy: 0.1065 - val_loss: 1.4791 - val_categorical_accuracy: 0.1052 - lr: 2.8184e-05\n",
      "Epoch 53/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9059 - categorical_accuracy: 0.1047 - val_loss: 1.4838 - val_categorical_accuracy: 0.1076 - lr: 2.5119e-05\n",
      "Epoch 54/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9118 - categorical_accuracy: 0.1062 - val_loss: 1.4793 - val_categorical_accuracy: 0.1029 - lr: 2.2387e-05\n",
      "Epoch 55/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9091 - categorical_accuracy: 0.1055 - val_loss: 1.4809 - val_categorical_accuracy: 0.1055 - lr: 1.9953e-05\n",
      "Epoch 56/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9070 - categorical_accuracy: 0.1070 - val_loss: 1.4858 - val_categorical_accuracy: 0.1072 - lr: 1.7783e-05\n",
      "Epoch 57/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9161 - categorical_accuracy: 0.1062 - val_loss: 1.4815 - val_categorical_accuracy: 0.1078 - lr: 1.5849e-05\n",
      "Epoch 58/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9070 - categorical_accuracy: 0.1065 - val_loss: 1.4792 - val_categorical_accuracy: 0.1039 - lr: 1.4125e-05\n",
      "Epoch 59/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9094 - categorical_accuracy: 0.1053 - val_loss: 1.4820 - val_categorical_accuracy: 0.1060 - lr: 1.2589e-05\n",
      "Epoch 60/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9092 - categorical_accuracy: 0.1062 - val_loss: 1.4801 - val_categorical_accuracy: 0.1045 - lr: 1.1220e-05\n",
      "Epoch 61/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9083 - categorical_accuracy: 0.1062 - val_loss: 1.4812 - val_categorical_accuracy: 0.1036 - lr: 1.0000e-05\n",
      "Epoch 62/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9026 - categorical_accuracy: 0.1065 - val_loss: 1.4799 - val_categorical_accuracy: 0.1025 - lr: 8.9125e-06\n",
      "Epoch 63/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9054 - categorical_accuracy: 0.1059 - val_loss: 1.4831 - val_categorical_accuracy: 0.1051 - lr: 7.9433e-06\n",
      "Epoch 64/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9141 - categorical_accuracy: 0.1050 - val_loss: 1.4802 - val_categorical_accuracy: 0.1068 - lr: 7.0795e-06\n",
      "Epoch 65/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9132 - categorical_accuracy: 0.1051 - val_loss: 1.4856 - val_categorical_accuracy: 0.1025 - lr: 6.3096e-06\n",
      "Epoch 66/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9066 - categorical_accuracy: 0.1063 - val_loss: 1.4817 - val_categorical_accuracy: 0.1070 - lr: 5.6234e-06\n",
      "Epoch 67/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9082 - categorical_accuracy: 0.1050 - val_loss: 1.4851 - val_categorical_accuracy: 0.1067 - lr: 5.0119e-06\n",
      "Epoch 68/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9084 - categorical_accuracy: 0.1052 - val_loss: 1.4809 - val_categorical_accuracy: 0.1046 - lr: 4.4668e-06\n",
      "Epoch 69/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9091 - categorical_accuracy: 0.1054 - val_loss: 1.4874 - val_categorical_accuracy: 0.1099 - lr: 3.9811e-06\n",
      "Epoch 70/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9140 - categorical_accuracy: 0.1063 - val_loss: 1.4804 - val_categorical_accuracy: 0.1058 - lr: 3.5481e-06\n",
      "Epoch 71/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9117 - categorical_accuracy: 0.1051 - val_loss: 1.4808 - val_categorical_accuracy: 0.1065 - lr: 3.1623e-06\n",
      "Epoch 72/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9081 - categorical_accuracy: 0.1050 - val_loss: 1.4805 - val_categorical_accuracy: 0.1074 - lr: 2.8184e-06\n",
      "Epoch 73/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9137 - categorical_accuracy: 0.1051 - val_loss: 1.4846 - val_categorical_accuracy: 0.1048 - lr: 2.5119e-06\n",
      "Epoch 74/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9102 - categorical_accuracy: 0.1055 - val_loss: 1.4873 - val_categorical_accuracy: 0.1097 - lr: 2.2387e-06\n",
      "Epoch 75/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9098 - categorical_accuracy: 0.1068 - val_loss: 1.4846 - val_categorical_accuracy: 0.1078 - lr: 1.9953e-06\n",
      "Epoch 76/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9093 - categorical_accuracy: 0.1069 - val_loss: 1.4885 - val_categorical_accuracy: 0.1084 - lr: 1.7783e-06\n",
      "Epoch 77/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9059 - categorical_accuracy: 0.1057 - val_loss: 1.4887 - val_categorical_accuracy: 0.1099 - lr: 1.5849e-06\n",
      "Epoch 78/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9112 - categorical_accuracy: 0.1054 - val_loss: 1.4817 - val_categorical_accuracy: 0.1068 - lr: 1.4125e-06\n",
      "Epoch 79/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9077 - categorical_accuracy: 0.1057 - val_loss: 1.4831 - val_categorical_accuracy: 0.1066 - lr: 1.2589e-06\n",
      "Epoch 80/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9036 - categorical_accuracy: 0.1066 - val_loss: 1.4839 - val_categorical_accuracy: 0.1076 - lr: 1.1220e-06\n",
      "Epoch 81/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9057 - categorical_accuracy: 0.1054 - val_loss: 1.4823 - val_categorical_accuracy: 0.1057 - lr: 1.0000e-06\n",
      "Epoch 82/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9090 - categorical_accuracy: 0.1059 - val_loss: 1.4840 - val_categorical_accuracy: 0.1063 - lr: 8.9125e-07\n",
      "Epoch 83/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9065 - categorical_accuracy: 0.1054 - val_loss: 1.4835 - val_categorical_accuracy: 0.1050 - lr: 7.9433e-07\n",
      "Epoch 84/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9045 - categorical_accuracy: 0.1057 - val_loss: 1.4847 - val_categorical_accuracy: 0.1085 - lr: 7.0795e-07\n",
      "Epoch 85/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9089 - categorical_accuracy: 0.1058 - val_loss: 1.4856 - val_categorical_accuracy: 0.1068 - lr: 6.3096e-07\n",
      "Epoch 86/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9039 - categorical_accuracy: 0.1057 - val_loss: 1.4823 - val_categorical_accuracy: 0.1041 - lr: 5.6234e-07\n",
      "Epoch 87/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9148 - categorical_accuracy: 0.1054 - val_loss: 1.4813 - val_categorical_accuracy: 0.1076 - lr: 5.0119e-07\n",
      "Epoch 88/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9086 - categorical_accuracy: 0.1068 - val_loss: 1.4834 - val_categorical_accuracy: 0.1035 - lr: 4.4668e-07\n",
      "Epoch 89/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9108 - categorical_accuracy: 0.1051 - val_loss: 1.4849 - val_categorical_accuracy: 0.1043 - lr: 3.9811e-07\n",
      "Epoch 90/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9151 - categorical_accuracy: 0.1058 - val_loss: 1.4822 - val_categorical_accuracy: 0.1047 - lr: 3.5481e-07\n",
      "Epoch 91/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9104 - categorical_accuracy: 0.1064 - val_loss: 1.4868 - val_categorical_accuracy: 0.1053 - lr: 3.1623e-07\n",
      "Epoch 92/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9086 - categorical_accuracy: 0.1052 - val_loss: 1.4787 - val_categorical_accuracy: 0.1057 - lr: 2.8184e-07\n",
      "Epoch 93/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9106 - categorical_accuracy: 0.1057 - val_loss: 1.4815 - val_categorical_accuracy: 0.1054 - lr: 2.5119e-07\n",
      "Epoch 94/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9052 - categorical_accuracy: 0.1052 - val_loss: 1.4831 - val_categorical_accuracy: 0.1074 - lr: 2.2387e-07\n",
      "Epoch 95/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9089 - categorical_accuracy: 0.1054 - val_loss: 1.4830 - val_categorical_accuracy: 0.1091 - lr: 1.9953e-07\n",
      "Epoch 96/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9098 - categorical_accuracy: 0.1059 - val_loss: 1.4858 - val_categorical_accuracy: 0.1060 - lr: 1.7783e-07\n",
      "Epoch 97/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9079 - categorical_accuracy: 0.1068 - val_loss: 1.4828 - val_categorical_accuracy: 0.1073 - lr: 1.5849e-07\n",
      "Epoch 98/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9116 - categorical_accuracy: 0.1062 - val_loss: 1.4826 - val_categorical_accuracy: 0.1059 - lr: 1.4125e-07\n",
      "Epoch 99/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9072 - categorical_accuracy: 0.1040 - val_loss: 1.4878 - val_categorical_accuracy: 0.1093 - lr: 1.2589e-07\n",
      "Epoch 100/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9075 - categorical_accuracy: 0.1062 - val_loss: 1.4854 - val_categorical_accuracy: 0.1095 - lr: 1.1220e-07\n",
      "Epoch 101/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9126 - categorical_accuracy: 0.1059 - val_loss: 1.4796 - val_categorical_accuracy: 0.1075 - lr: 1.0000e-07\n",
      "Epoch 102/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9144 - categorical_accuracy: 0.1053 - val_loss: 1.4845 - val_categorical_accuracy: 0.1090 - lr: 8.9125e-08\n",
      "Epoch 103/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9101 - categorical_accuracy: 0.1048 - val_loss: 1.4807 - val_categorical_accuracy: 0.1040 - lr: 7.9433e-08\n",
      "Epoch 104/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9062 - categorical_accuracy: 0.1056 - val_loss: 1.4872 - val_categorical_accuracy: 0.1056 - lr: 7.0795e-08\n",
      "Epoch 105/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9051 - categorical_accuracy: 0.1059 - val_loss: 1.4864 - val_categorical_accuracy: 0.1091 - lr: 6.3096e-08\n",
      "Epoch 106/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9056 - categorical_accuracy: 0.1055 - val_loss: 1.4877 - val_categorical_accuracy: 0.1069 - lr: 5.6234e-08\n",
      "Epoch 107/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9083 - categorical_accuracy: 0.1046 - val_loss: 1.4830 - val_categorical_accuracy: 0.1078 - lr: 5.0119e-08\n",
      "Epoch 108/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9069 - categorical_accuracy: 0.1065 - val_loss: 1.4784 - val_categorical_accuracy: 0.1031 - lr: 4.4668e-08\n",
      "Epoch 109/1000\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.9032 - categorical_accuracy: 0.1066 - val_loss: 1.4856 - val_categorical_accuracy: 0.1083 - lr: 3.9811e-08\n",
      "Epoch 110/1000\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 0.9073 - categorical_accuracy: 0.1063 - val_loss: 1.4855 - val_categorical_accuracy: 0.1050 - lr: 3.5481e-08\n",
      "Epoch 111/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9100 - categorical_accuracy: 0.1062 - val_loss: 1.4823 - val_categorical_accuracy: 0.1059 - lr: 3.1623e-08\n",
      "Epoch 112/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9059 - categorical_accuracy: 0.1053 - val_loss: 1.4857 - val_categorical_accuracy: 0.1089 - lr: 2.8184e-08\n",
      "Epoch 113/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9122 - categorical_accuracy: 0.1057 - val_loss: 1.4857 - val_categorical_accuracy: 0.1067 - lr: 2.5119e-08\n",
      "Epoch 114/1000\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 0.9063 - categorical_accuracy: 0.1055 - val_loss: 1.4825 - val_categorical_accuracy: 0.1047 - lr: 2.2387e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model_bn.fit(X_train_full,\\\n",
    "                    y_train_full,\\\n",
    "                    epochs=1000,\\\n",
    "                    validation_split=0.2,\\\n",
    "                   callbacks=[early_stop_cb,lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb1d81",
   "metadata": {},
   "source": [
    "Replace bn with selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b9379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 100)               307300    \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_38 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_39 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_selu = keras.models.Sequential([keras.layers.Flatten(input_shape=[32,32,3])])\n",
    "\n",
    "for i in range(1,21):\n",
    "    model_selu.add(keras.layers.Dense(100,kernel_initializer=tf.keras.initializers.LecunNormal(seed=None)))\n",
    "    model_selu.add(keras.layers.Activation(\"selu\"))\n",
    "model_selu.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "model_selu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86b65f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize inputs\n",
    "train_mean = np.mean(X_train_full, axis=0)\n",
    "train_std = np.std(X_train_full, axis=0)\n",
    "X_train_norm = (X_train_full - train_mean) / train_std\n",
    "X_test_norm = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e99b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selu.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\\\n",
    "              optimizer=\"Nadam\",\\\n",
    "              metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea07d53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3450 - categorical_accuracy: 0.1040 - val_loss: 2.3360 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3470 - categorical_accuracy: 0.0872 - val_loss: 2.3315 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0089\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3490 - categorical_accuracy: 0.1144 - val_loss: 2.3406 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0079\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3481 - categorical_accuracy: 0.0920 - val_loss: 2.3200 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0071\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3508 - categorical_accuracy: 0.1072 - val_loss: 2.3800 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0063\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3515 - categorical_accuracy: 0.1104 - val_loss: 2.3385 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0056\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3493 - categorical_accuracy: 0.1128 - val_loss: 2.3305 - val_categorical_accuracy: 1.0000 - lr: 0.0050\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3464 - categorical_accuracy: 0.1032 - val_loss: 2.4000 - val_categorical_accuracy: 1.0000 - lr: 0.0045\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3467 - categorical_accuracy: 0.1016 - val_loss: 2.3214 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0040\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3435 - categorical_accuracy: 0.1112 - val_loss: 2.3240 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0035\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3409 - categorical_accuracy: 0.1024 - val_loss: 2.3501 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0032\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3419 - categorical_accuracy: 0.0856 - val_loss: 2.3273 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0028\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3390 - categorical_accuracy: 0.0752 - val_loss: 2.3319 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0025\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3346 - categorical_accuracy: 0.1240 - val_loss: 2.3327 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0022\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3337 - categorical_accuracy: 0.0632 - val_loss: 2.3235 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0020\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3305 - categorical_accuracy: 0.0880 - val_loss: 2.3593 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0018\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3288 - categorical_accuracy: 0.1392 - val_loss: 2.3283 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0016\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3249 - categorical_accuracy: 0.0928 - val_loss: 2.3339 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0014\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3245 - categorical_accuracy: 0.0984 - val_loss: 2.3138 - val_categorical_accuracy: 1.0000 - lr: 0.0013\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3233 - categorical_accuracy: 0.0744 - val_loss: 2.3325 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0011\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3209 - categorical_accuracy: 0.0888 - val_loss: 2.3307 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3200 - categorical_accuracy: 0.1144 - val_loss: 2.3310 - val_categorical_accuracy: 0.0000e+00 - lr: 8.9125e-04\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3178 - categorical_accuracy: 0.1000 - val_loss: 2.3179 - val_categorical_accuracy: 0.0000e+00 - lr: 7.9433e-04\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3174 - categorical_accuracy: 0.0992 - val_loss: 2.3305 - val_categorical_accuracy: 0.0000e+00 - lr: 7.0795e-04\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3145 - categorical_accuracy: 0.0904 - val_loss: 2.3115 - val_categorical_accuracy: 0.0000e+00 - lr: 6.3096e-04\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3137 - categorical_accuracy: 0.1224 - val_loss: 2.3105 - val_categorical_accuracy: 0.0000e+00 - lr: 5.6234e-04\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3123 - categorical_accuracy: 0.0752 - val_loss: 2.3110 - val_categorical_accuracy: 0.0000e+00 - lr: 5.0119e-04\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3121 - categorical_accuracy: 0.1096 - val_loss: 2.3189 - val_categorical_accuracy: 0.0000e+00 - lr: 4.4668e-04\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3101 - categorical_accuracy: 0.0712 - val_loss: 2.3083 - val_categorical_accuracy: 0.0000e+00 - lr: 3.9811e-04\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3102 - categorical_accuracy: 0.1080 - val_loss: 2.3078 - val_categorical_accuracy: 0.0000e+00 - lr: 3.5481e-04\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3090 - categorical_accuracy: 0.0984 - val_loss: 2.3094 - val_categorical_accuracy: 0.0000e+00 - lr: 3.1623e-04\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3091 - categorical_accuracy: 0.0912 - val_loss: 2.3092 - val_categorical_accuracy: 0.0000e+00 - lr: 2.8184e-04\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 11s 8ms/step - loss: 2.3081 - categorical_accuracy: 0.1112 - val_loss: 2.3102 - val_categorical_accuracy: 1.0000 - lr: 2.5119e-04\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3078 - categorical_accuracy: 0.0792 - val_loss: 2.3095 - val_categorical_accuracy: 0.0000e+00 - lr: 2.2387e-04\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3069 - categorical_accuracy: 0.1000 - val_loss: 2.3088 - val_categorical_accuracy: 0.0000e+00 - lr: 1.9953e-04\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3065 - categorical_accuracy: 0.0904 - val_loss: 2.3067 - val_categorical_accuracy: 0.0000e+00 - lr: 1.7783e-04\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3063 - categorical_accuracy: 0.0432 - val_loss: 2.3052 - val_categorical_accuracy: 0.0000e+00 - lr: 1.5849e-04\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3057 - categorical_accuracy: 0.1320 - val_loss: 2.3054 - val_categorical_accuracy: 0.0000e+00 - lr: 1.4125e-04\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3053 - categorical_accuracy: 0.1072 - val_loss: 2.3051 - val_categorical_accuracy: 0.0000e+00 - lr: 1.2589e-04\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3051 - categorical_accuracy: 0.0896 - val_loss: 2.3052 - val_categorical_accuracy: 0.0000e+00 - lr: 1.1220e-04\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3050 - categorical_accuracy: 0.0768 - val_loss: 2.3074 - val_categorical_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3049 - categorical_accuracy: 0.0576 - val_loss: 2.3052 - val_categorical_accuracy: 0.0000e+00 - lr: 8.9125e-05\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3047 - categorical_accuracy: 0.0760 - val_loss: 2.3032 - val_categorical_accuracy: 1.0000 - lr: 7.9433e-05\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3043 - categorical_accuracy: 0.1256 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 7.0795e-05\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3040 - categorical_accuracy: 0.1368 - val_loss: 2.3041 - val_categorical_accuracy: 0.0000e+00 - lr: 6.3096e-05\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3044 - categorical_accuracy: 0.0896 - val_loss: 2.3034 - val_categorical_accuracy: 0.0000e+00 - lr: 5.6234e-05\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3037 - categorical_accuracy: 0.0072 - val_loss: 2.3039 - val_categorical_accuracy: 0.0000e+00 - lr: 5.0119e-05\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3038 - categorical_accuracy: 0.0888 - val_loss: 2.3051 - val_categorical_accuracy: 0.0000e+00 - lr: 4.4668e-05\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3037 - categorical_accuracy: 0.0616 - val_loss: 2.3034 - val_categorical_accuracy: 0.0000e+00 - lr: 3.9811e-05\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3036 - categorical_accuracy: 0.0632 - val_loss: 2.3039 - val_categorical_accuracy: 0.0000e+00 - lr: 3.5481e-05\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3035 - categorical_accuracy: 0.1048 - val_loss: 2.3035 - val_categorical_accuracy: 0.0000e+00 - lr: 3.1623e-05\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3032 - categorical_accuracy: 0.0936 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 2.8184e-05\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3033 - categorical_accuracy: 0.0072 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 2.5119e-05\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3031 - categorical_accuracy: 0.0096 - val_loss: 2.3033 - val_categorical_accuracy: 0.0000e+00 - lr: 2.2387e-05\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3031 - categorical_accuracy: 0.0912 - val_loss: 2.3038 - val_categorical_accuracy: 0.0000e+00 - lr: 1.9953e-05\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3031 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3035 - val_categorical_accuracy: 0.0000e+00 - lr: 1.7783e-05\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3030 - categorical_accuracy: 0.0040 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.5849e-05\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3031 - categorical_accuracy: 8.0000e-04 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 1.4125e-05\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3030 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3030 - val_categorical_accuracy: 0.0000e+00 - lr: 1.2589e-05\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3029 - categorical_accuracy: 0.0384 - val_loss: 2.3030 - val_categorical_accuracy: 0.0000e+00 - lr: 1.1220e-05\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3029 - categorical_accuracy: 0.0352 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3029 - categorical_accuracy: 0.0696 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 8.9125e-06\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3028 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3030 - val_categorical_accuracy: 0.0000e+00 - lr: 7.9433e-06\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3028 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 7.0795e-06\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.1112 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 6.3096e-06\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3028 - categorical_accuracy: 0.2328 - val_loss: 2.3029 - val_categorical_accuracy: 0.0000e+00 - lr: 5.6234e-06\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0600 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 5.0119e-06\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0496 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 4.4668e-06\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 3.9811e-06\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 3.5481e-06\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3028 - val_categorical_accuracy: 0.0000e+00 - lr: 3.1623e-06\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 2.8184e-06\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 2.5119e-06\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 2.2387e-06\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3027 - categorical_accuracy: 0.1528 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.9953e-06\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.7783e-06\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.5849e-06\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.4125e-06\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.2589e-06\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.1220e-06\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 8.9125e-07\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 7.9433e-07\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 7.0795e-07\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 6.3096e-07\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 5.6234e-07\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 5.0119e-07\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 4.4668e-07\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 3.9811e-07\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 3.5481e-07\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 3.1623e-07\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 2.8184e-07\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 2.5119e-07\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 2.2387e-07\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.9953e-07\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.7783e-07\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.5849e-07\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.4125e-07\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.2589e-07\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.3026 - categorical_accuracy: 0.0000e+00 - val_loss: 2.3027 - val_categorical_accuracy: 0.0000e+00 - lr: 1.1220e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model_selu.fit(X_train_norm,\\\n",
    "                    y_train_full,\\\n",
    "                    epochs=100,\\\n",
    "                    validation_split=0.2,\\\n",
    "                   callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b1fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
